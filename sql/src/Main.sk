module SKDB;

/*****************************************************************************/
/* Helpers */
/*****************************************************************************/

@export("getVersion")
fun getVersion(): String {
  `${SkargoVersion.kVersion} (${SkargoVersion.kCommit})`
}

fun getFieldNames(
  context: readonly SKStore.Context,
  dirName: SKStore.DirName,
): Array<String> {
  mcontext = context.mclone();
  tables = SKDB.getTableDir(mcontext);
  dirNameStr = dirName.toString();
  iter = dirNameStr.getIter();
  _ = iter.next();
  tableName = dirNameStr.sub(iter, dirNameStr.length() - 2);
  arr = tables.getArray(mcontext, SKStore.SID(tableName));
  if (arr.size() == 0) {
    print_error("There is no sql table associated with dir: " + dirNameStr);
    skipExit(44);
  };
  dirDescr = arr[0];
  dirDescr.schema.map(x -> x.name.origName);
}

fun fixUpDirName(dirNameStr: String): SKStore.DirName {
  chars = dirNameStr.chars();
  SKStore.DirName::create(
    (if (chars[0] != '/') "/" else "") +
      dirNameStr +
      (if (chars[chars.size() - 1] != '/') "/" else ""),
  )
}

// Read a single line from stdin, decode it to a JSON Object, expected
// to be a map from key strings (parameter names) to values.
fun queryParams(options: SKDB.Options): Map<String, SKDB.Value> {
  if (!options.expectQueryParams) {
    return Map[];
  };
  read_line() match {
  | Some(line) -> decodeParams(line)

  | None() ->
    print_error("Reading stdin for statement parameters failed\n");
    skipExit(2)
  }
}

fun slurpStdin(): String {
  lines = mutable Vector[];
  try {
    loop {
      read_line() match {
      | None() -> break void
      | Some(l) -> lines.push(l)
      }
    }
  } catch {
  | EndOfFile _ -> void
  | exn -> throw exn
  };
  lines.join("\n")
}

/*****************************************************************************/
/* Main */
/*****************************************************************************/

untracked fun main(): void {
  saved = SKStore.newObstack();
  cmd = Cli.Command("skdb")
    .about("The SQL database that tells you when your query results changed")
    .arg(Cli.StringArg("init").about("Initialize new SKStore runtime data"))
    .arg(
      Cli.StringArg("data").about("Use existing SKStore runtime data").global(),
    )
    .arg(Cli.BoolArg("backtrace").about("Internal use").global())
    .arg(Cli.BoolArg("sync").about("Sync to disk").global())
    .arg(
      Cli.StringArg("format")
        .default(if (isATTY() != 0) "table" else "sql")
        .about("Output format (sql, csv, json, or table)")
        .global(),
    )
    .arg(
      Cli.BoolArg("always-allow-joins")
        .about("Allow cross joins and joins outside of virtual views")
        .global(),
    )
    .arg(
      Cli.BoolArg("show-used-indexes")
        .about("Print indexes used by a query to stdout")
        .global(),
    )
    .arg(
      Cli.StringArg("capacity").about(
        "Initialize SKStore runtime with given capacity",
      ),
    )
    .arg(
      Cli.BoolArg("expect-query-params").about(
        "Read values of named parameters which may appear in the statement. The parameter values must be provided via stdin, on a single line, as an encoded JSON Object where the keys are the parameter names and the values will be interpreted as SQL values.",
      ),
    )
    .subcommand(Cli.Command("sessions").about("List the current subscriptions"))
    .subcommand(Cli.Command("compact").about("Compact the db"))
    .subcommand(
      Cli.Command("dump-table")
        .about("Print a specific table signature")
        .arg(Cli.StringArg("table").positional().required().about("Table name"))
        .arg(Cli.StringArg("table-suffix").about("Optional suffix")),
    )
    .subcommand(
      Cli.Command("dump-tables")
        .about("Dumps the tables in SQL format")
        .arg(Cli.StringArg("table-suffix").about("Optional suffix")),
    )
    .subcommand(
      Cli.Command("dump-inserts").about("Dump the inserts in SQL format"),
    )
    .subcommand(
      Cli.Command("dump-view")
        .about("Print a specific view in SQL format")
        .arg(Cli.StringArg("view").positional().required().about("View name")),
    )
    .subcommand(Cli.Command("dump-views").about("Dump the views in SQL format"))
    .subcommand(
      Cli.Command("dump").about("Dumps tables/inserts/views in SQL format"),
    )
    .subcommand(
      Cli.Command("migrate").about("Dumps to a new schema, read on stdin"),
    )
    .subcommand(
      Cli.Command("csv-field")
        .about("Output a specific CSV field")
        .arg(
          Cli.StringArg("field").positional().required().about("Field number"),
        ),
    )
    .subcommand(
      Cli.Command("load-csv")
        .about("Load CSV values into table")
        .arg(Cli.StringArg("table").positional().required().about("Table name"))
        // TODO: Why is `--user` only offered for CSV variants?
        .arg(Cli.StringArg("user").about("Name of the user")),
    )
    .subcommand(Cli.Command("size").about("Output the size of the db"))
    .subcommand(
      Cli.Command("diff")
        .about("Send the diff from session")
        .arg(
          Cli.StringArg("session-id")
            .positional()
            .required()
            .about("Session id"),
        )
        // if not specified, diff will read a multi-table spec from stdin.
        .arg(Cli.StringArg("since").about("Starting time of the diff")),
    )
    .subcommand(
      Cli.Command("disconnect")
        .about("Disconnect a session")
        .arg(
          Cli.StringArg("session-id")
            .positional()
            .required()
            .about("Session id"),
        ),
    )
    .subcommand(
      Cli.Command("write")
        .about("Write data from stdin into a directory")
        .arg(
          Cli.StringArg("directory")
            .positional()
            .required()
            .about("Directory name"),
        ),
    )
    .subcommand(
      Cli.Command("watermark")
        .about("Get the watermark for table TABLE")
        .arg(
          Cli.StringArg("source")
            .required()
            .about("Globally unique identity of this write stream"),
        )
        .arg(
          Cli.StringArg("table").positional().required().about("Table name"),
        ),
    )
    .subcommand(
      Cli.Command("replication-id")
        .about("Get a unique id for CLIENT-UUID")
        .arg(
          Cli.StringArg("client-uuid")
            .positional()
            .required()
            .about("UUID of the client instance"),
        ),
    )
    .subcommand(
      Cli.Command("write-csv")
        .about("Write data from stdin into a directory in CSV format")
        .arg(
          Cli.StringArg("source").about(
            "Globally unique identity of this write stream",
          ),
        )
        .arg(Cli.StringArg("user").about("Name of the user")),
    )
    .subcommand(
      Cli.Command("tail")
        .about("Tail changes on a directory")
        .arg(
          Cli.StringArg("session-id")
            .positional()
            .required()
            .about("Session id"),
        )
        .arg(Cli.StringArg("filter").positional().about("SQL filter condition"))
        .arg(
          Cli.BoolArg("follow")
            .long("follow")
            .short("f")
            .about("Output appended data as the database grows"),
        )
        .arg(
          Cli.StringArg("since")
            .long("since")
            .about("Starting time of the tail"),
        )
        .arg(Cli.StringArg("user").about("Name of the user"))
        .arg(
          Cli.BoolArg("expect-query-params").about(
            "Read values of named parameters which may appear in the filter condition. The parameter values must be provided via stdin, on a single line, as an encoded JSON Object where the keys are the parameter names and the values will be interpreted as SQL values.",
          ),
        ),
    )
    .subcommand(
      Cli.Command("subscribe")
        .about("Subscribe to a directory change")
        .arg(Cli.ArrayArg("views").positional().required().about("Views"))
        .arg(Cli.BoolArg("connect").about("Send the initial state first"))
        .arg(
          Cli.StringArg("updates").about(
            "Name of the file where the updates will be written",
          ),
        )
        .arg(
          Cli.StringArg("notify").about(
            "Name of the file updates with time of the last change",
          ),
        )
        .arg(Cli.StringArg("ignore-source").about("Write stream to ignore")),
    )
    .subcommand(
      Cli.Command("can-mirror")
        .about("Check that a table is eligible for mirroring")
        .arg(
          Cli.StringArg("table").positional().required().about("Table name"),
        ),
    )
    .subcommand(Cli.Command("replay").about("Replay a diff"))
    .subcommand(
      Cli.Command("toggle-view")
        .about("Toggle view status of specified table")
        .arg(
          Cli.StringArg("table").positional().required().about("Table name"),
        ),
    )
    .subcommand(Cli.Command("debug").about("TODO"))
    .help();

  try {
    args = cmd.parseArgs();
    options = SKDB.Options{
      backtrace => args.getBool("backtrace"),
      alwaysAllowJoins => args.getBool("always-allow-joins"),
      sync => args.getBool("sync"),
      showUsedIndexes => args.getBool("show-used-indexes"),
      format => args.getString("format") match {
      | "csv" -> SKDB.OFK_CSV()
      | "json" -> SKDB.OFK_JSON()
      | "sql" -> SKDB.OFK_SQL()
      | "js" -> SKDB.OFK_JS()
      | "table" -> SKDB.OFK_Table()
      | f -> invariant_violation(`Unsupported format: ${f}`)
      },
      expectQueryParams => args.getBool("expect-query-params"),
    };

    subcmd_handler = args.subcommand
      .map(subcmd ->
        subcmd match {
        | "sessions" -> execSessions
        | "compact" -> execCompact
        | "dump-table" -> execDumpTable
        | "dump-tables" -> execDumpTables
        | "dump-inserts" -> execDumpInserts
        | "dump-view" -> execDumpView
        | "dump-views" -> execDumpViews
        | "dump" -> execDump
        | "migrate" -> execMigrate
        | "load-csv" -> execLoadCsv
        | "csv-field" -> execCsvField
        | "size" -> execSize
        | "diff" -> execDiff
        | "disconnect" -> execDisconnect
        | "write" -> execWrite
        | "tail" -> execTail
        | "watermark" -> execWatermark
        | "replication-id" -> execReplicationId
        | "write-csv" -> execWriteCsv
        | "subscribe" -> execSubscribe
        | "can-mirror" -> execCanMirror
        | "replay" -> execReplay
        | "toggle-view" -> execToggleView
        | "debug" -> execDebug
        | _ -> invariant_violation(`Unknown subcommand ${subcmd}`)
        }
      )
      .default((args, options) -> {
        // NOTE: This should be a subcommand, but the `--init` flag is currently
        // hardcoded in the runtime. It should be revisited once the runtime has
        // a proper two-step init API for persistence.
        if (args.maybeGetString("init") is Some _) {
          _ = SKStore.gContextInit(SKDB.makeSqlContext().clone());
          return void
        } else if (args.maybeGetString("capacity") is Some _) {
          print_error("cannot use capacity without init");
          skipExit(2)
        };
        // TODO: If `--user` is actually needed, reinstate it. It was clashing with
        // other options and was removed for convenience.
        // user = argMap.maybeGet("user") match {
        //   | Some(AP.StringValue{value => userID}) -> Some(userID)
        //   | _ -> None()
        //   };
        params = queryParams(options);
        SKDB.eval(options, params, /* user = */ None())
      });
    subcmd_handler(args, options);
  } catch {
  | exn ->
    SKStore.destroyObstack(saved);
    throw exn
  };
  SKStore.destroyObstack(saved);
}

@wasm_export("SKDB_factory")
untracked fun factory(): void {
  main();
}

private fun ensureContext(args: Cli.ParseResults): void {
  if (SKStore.gHasContext() == 0) {
    invariant(args.maybeGetString("data") is None _);
    print_error("Error: option --data is missing");
    skipExit(2);
  };
}

fun execSessions(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  SKDB.runSql(options, context ~> {
    for (id => sub in context.sessions) {
      print_string(
        id.toString() + "\t" + sub.dirSubs.map(d -> d.entity).join(","),
      );
    };
    SKStore.CStop(None())
  })
}

fun execCompact(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  SKDB.runLockedSql(options, context ~> {
    for (_dirName => dir in context.dirs.state) {
      dir match {
      | edir @ SKStore.EagerDir _ ->
        !edir = edir.purge(context);
        context.setDir(edir.dirName, edir)
      | _ -> void
      }
    }
  })
}

fun execDumpTable(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  tableName = args.getString("table");
  suffix = args.maybeGetString("table-suffix");
  SKDB.runSql(options, context ~> {
    SKDB.dumpTable(context, tableName.lowercase(), suffix);
    SKStore.CStop(None())
  })
}

fun execDumpTables(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  suffix = args.maybeGetString("table-suffix");
  SKDB.runSql(options, context ~> {
    SKDB.dumpTables(context, suffix);
    SKStore.CStop(None())
  })
}

fun execDumpInserts(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  SKDB.runSql(options, context ~> {
    SKDB.dumpInserts(context);
    SKStore.CStop(None())
  })
}

fun execDumpView(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  viewName = args.getString("view");
  SKDB.runSql(options, context ~> {
    SKDB.dumpView(context, viewName.lowercase());
    SKStore.CStop(None())
  })
}

fun execDumpViews(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  SKDB.runSql(options, context ~> {
    SKDB.dumpViews(context);
    SKStore.CStop(None())
  })
}

fun execDump(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  SKDB.runSql(options, context ~> {
    SKDB.dumpTables(context, None());
    SKDB.dumpInserts(context);
    SKDB.dumpViews(context);
    SKStore.CStop(None())
  })
}

fun execMigrate(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  stmts = SKDB.slurpStmts(options);
  SKDB.runSql(options, context ~> {
    schema = SKDB.getTables(context);
    def = migrationDiff(stmts, schema);
    SKDB.dumpAdjustedInserts(context, def);
    SKStore.CStop(None())
  })
}

fun execLoadCsv(args: Cli.ParseResults, options: SKDB.Options): void {
  name = SKDB.Name::create(args.getString("table"));
  SKDB.runSql(options, context ~> {
    table = context.getGlobal("CSV_TABLE") match {
    | None() ->
      tableDescr = SKDB.getTable(context, 0, name);
      context.setGlobal("CSV_TABLE", tableDescr);
      tableDescr
    | Some(x) -> SKDB.DirDescr::type(x)
    };
    line = context.getGlobal("Line") match {
    | None() -> mutable Ref(1)
    | Some(file) -> mutable Ref(SKStore.IntFile::type(file).value)
    };
    user = args.maybeGetString("user") match {
    | None() -> None()
    | Some(userID) -> Some(SKDB.UserFile::create(context, userID))
    };
    try {
      contextOp = SKCSV.insert(context, line, options, table, user);
      context.setGlobal("Line", SKStore.IntFile(line.get()));
      contextOp
    } catch {
    | exn ->
      print_error("Error, line " + line.get() + ": " + exn.getMessage());
      skipExit(23)
    };
  })
}

fun execCsvField(args: Cli.ParseResults, _options: SKDB.Options): void {
  fieldNbr = args.getString("field").toInt();
  line = mutable Ref(1);
  loop {
    (eof, rows) = SKCSV.parseCsv(line, x ~> x);
    for (row in rows) {
      if (fieldNbr < 0 || fieldNbr >= row.size()) continue;
      str = row[fieldNbr].i1;
      print_string(str);
    };
    if (eof) return void;
  }
}

fun execSize(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  SKDB.runSql(options, _context ~> {
    SKStore.printPersistentSize();
    SKStore.CStop(None())
  })
}

fun execDiff(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  sessionID = args.getString("session-id").toInt();
  since = args.maybeGetString("since").map(v -> v.toInt());
  SKDB.runSql(options, origContext ~> {
    context = origContext.mclone();
    sub = context.sessions.maybeGet(sessionID) match {
    | None() ->
      print_error("Error: session not found");
      skipExit(2)
    | Some(x) -> x
    };

    sinceForTable = since match {
    | None() ->
      input = slurpStdin();
      spec = decodeDiffSpec(input);
      (name -> spec.get(name))
    | Some(v) -> (_ -> SKStore.Tick(v))
    };

    diffSpec = sub.dirSubs.map(dirsub -> {
      tableName = SKDB.Name::create(
        dirsub.dirName.dirName.stripPrefix("/").stripSuffix("/"),
      );
      (dirsub, sinceForTable(tableName))
    });

    origContext.setGlobal("Stdout", SKDB.StdoutDiff(diffSpec));
    SKStore.CStop(None())
  })
}

fun execDisconnect(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  sessionID = args.getString("session-id").toInt();
  SKDB.runLockedSql(options, context ~> {
    context.sessions.maybeGet(sessionID) match {
    | None() ->
      print_error("Error: session not found");
      skipExit(2)
    | Some(_) -> context.!sessions = context.sessions.remove(sessionID)
    };
  })
}

fun execWrite(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  dirNameStr = args.getString("directory");
  SKDB.runSql(options, context ~> {
    SKStore.writeFromStdin(context, dirNameStr);
    SKStore.CStop(None())
  })
}

fun getSqlTableFromDirName(
  context: readonly SKStore.Context,
  dirName: SKStore.DirName,
): SKDB.DirDescr {
  dirNameStr = dirName.toString();
  !dirNameStr = dirName.toString().stripPrefix("/").stripSuffix("/");
  SKDB.getTable(context.mclone(), 0, SKDB.Name::create(dirNameStr))
}

fun execTail(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  sessionID = args.getString("session-id").toInt();
  followMode = args.getBool("follow");
  tick = args.maybeGetString("since") match {
  | Some(since) -> since.toInt()
  | _ -> 0
  };
  init = true;

  gContext = SKStore.gContextGet();
  (subFilter, dirName) = gContext.sessions.maybeGet(sessionID) match {
  | None() ->
    print_error("Error: session not found");
    skipExit(2)
  | Some(sub) if (sub.dirSubs.size() == 1) ->
    (sub.dirSubs[0].filter, sub.dirSubs[0].dirName)
  | Some(_) ->
    print_error("Error: tail only supports a single dir sub currently");
    skipExit(2)
  };

  tableName = SKDB.Name::create(
    dirName.toString().stripPrefix("/").stripSuffix("/"),
  );
  filter1 = args.maybeGetString("filter") match {
  | None() ->
    if (options.expectQueryParams) {
      print_error("Cannot pass parameters without filter condition");
      skipExit(2)
    };
    subFilter
  | Some(strCond) ->
    params = queryParams(options);
    compiler = SKDB.Compiler::create(false, options, 0, params);
    (_, ast) = SKDB.parseExpr(SKDB.Lexer(0, SKDB.Buffer(strCond)), 0);
    compilerContext = gContext.mclone();
    _ = compiler.compileFrom(
      compilerContext,
      Array[SKDB.FromName{name => SKDB.FName(tableName), asName => None()}],
    );
    e = compiler.compileExpr(compilerContext, ast) match {
    | SKDB.CIExpr(x) -> x
    | _ ->
      print_error("Unexpected type for filter expression");
      skipExit(2)
    };
    (context, isReset) ~> {
      mcontext = context.mclone();
      conditionFilter = subFilter(context, isReset);
      baseName -> {
        inputRow = baseName match {
        | SKDB.RowKey(row, _) -> row
        | _ ->
          print_error("Unexpected table entry type");
          skipExit(2)
        };
        evaluator = SKDB.ExprEvaluator(Array[inputRow], Array[], None());

        evaluator.evalCIExpr(mcontext, e) match {
        | SKDB.ANull()
        | SKDB.ADef(0) ->
          false
        | SKDB.AUndef()
        | SKDB.ADef(_) ->
          conditionFilter(baseName)
        }
      }
    }
  };

  userIDOpt = args.maybeGetString("user");
  filter = args.maybeGetString("user") match {
  | None() -> filter1
  | Some(userID) ->
    (context, isReset) ~> {
      user = SKDB.UserFile::create(context, userID);
      sqlTable = getSqlTableFromDirName(context, dirName);

      oldFilter = filter1(context, isReset);

      baseName -> {
        oldFilter(baseName) &&
          baseName match {
          | SKDB.RowKey(row, _) ->
            SKDB.checkUserCanReadRow(context, user, sqlTable, row) match {
            | SKDB.AROK() -> true
            | _ -> false
            }
          | _ ->
            print_error("Unexpected table entry type");
            skipExit(2)
          };
      }
    }
  };

  forceReset = false;

  loop {
    localObstack = SKStore.newObstack();
    context = SKStore.gContextGet();
    (sub, dirSub) = context.sessions.maybeGet(sessionID) match {
    | None() ->
      print_error("Error: session not found");
      skipExit(2)
    | Some(s) if (s.dirSubs.size() == 1) -> (s, s.dirSubs[0])
    | Some(_) ->
      print_error("Error: tail only supports a single dir sub currently");
      skipExit(2)
    };
    invariant(dirName == dirSub.dirName);

    SKDB.getFinalState(context, sub.destinationSource) match {
    | Some(SKDB.RSError()) ->
      print_raw(":reboot\n");
      break void
    | _ -> void
    };

    edir = context.unsafeGetEagerDir(dirName);
    format = options.format match {
    | SKDB.OFK_CSV() -> SKStore.OCSV()
    | SKDB.OFK_JSON() -> SKStore.OJSON(getFieldNames(context, dirName))
    | SKDB.OFK_SQL() -> SKStore.OSQL()
    | SKDB.OFK_JS() -> SKStore.OJS(getFieldNames(context, dirName))
    | SKDB.OFK_Table() -> SKStore.OTable(getFieldNames(context, dirName))
    };

    (isReset, changes) = edir.getChangesAfter(SKStore.Tick(tick), forceReset);
    !forceReset = false;

    // Write checkpoints out at least every `checkpointInterval` rows during
    // initialization, so that the client can start processing without waiting
    // for the full changeset.
    // this value is chosen based on some unscientific local testing
    checkpointInterval = if (init) 512 else Int::max;

    writer = mutable Debug.BufferedWriter(print_raw, 4096);
    producedOutput = edir.writeDiff(
      context,
      isReset,
      changes,
      writer,
      dirSub.entity,
      format,
      filter,
      dirSub.getDestinationWatermark(context),
      checkpointInterval,
    );
    // produce checkpoint for flushing and committing
    if (init || producedOutput) {
      // always do this on first iteration to ensure we output a
      // checkpoint without delay so that the downstreams knows that
      // it has received everything without waiting for the condvar
      // timeout
      writer.write(":" + context.tick.value.toString() + "\n");
      writer.flush();
      flushStdout();
    };

    !tick = context.tick.value;
    !init = false;
    lock = SKStore.unfreezeLock(sub.lock);
    cond = SKStore.unfreezeCond(sub.cond);
    SKStore.mutexLock(lock);
    while ({
      !forceReset &&
        {
          newContext = SKStore.gContextGet();
          followMode &&
            newContext.unsafeMaybeGetEagerDir(dirName) match {
            | None() -> false
            | Some(dir) ->
              (newIsReset, newChanges) = dir.getChangesAfter(
                SKStore.Tick(tick),
              );
              !newIsReset && newChanges.isEmpty()
            }
        }
    }) {
      timeoutSecs = 10;
      _ = SKStore.condTimedWait(cond, lock, UInt32::truncate(timeoutSecs));
      print_raw(":" + tick.toString() + "\n");
      flushStdout();
      if (
        SKDB.userPrivacyChanged(
          SKStore.gContextGet(),
          userIDOpt,
          SKStore.Tick(tick),
        )
      ) {
        !forceReset = true;
      };
    };
    SKStore.mutexUnlock(lock);
    SKStore.destroyObstack(localObstack);
    if (!followMode) {
      break void
    }
  }
}

fun execWatermark(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  tableName = args.getString("table").lowercase();
  source = args.getString("source").toIntOption();
  SKDB.runSql(options, context ~> {
    print_string(
      SKDB.getWatermark(context.clone(), tableName, source).default(
        SKStore.Tick(0),
      ).value,
    );
    SKStore.CStop(None())
  });
}

fun execReplicationId(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  clientUuid = args.getString("client-uuid").lowercase();
  SKDB.runSql(options, context ~> {
    clientsDirname = SKStore.DirName::create(`/clients/`);
    clientsDir = context.maybeGetDir(clientsDirname) match {
    | None() ->
      context.mkdir(SKStore.SID::keyType, SKStore.IntFile::type, clientsDirname)
    | Some(d) ->
      SKStore.EHandle(
        SKStore.SID::keyType,
        SKStore.IntFile::type,
        d.getDirName(),
      )
    };
    key = SKStore.SID::create(clientUuid);
    arr = clientsDir.unsafeGetArray(context, key);
    replicationSource = if (arr.size() > 0) {
      arr[0].value
    } else {
      source = SKStore.genSym(0);
      clientsDir.writeArray(context, key, Array[SKStore.IntFile(source)]);
      source
    };
    print_string(replicationSource);
    SKStore.CStop(None())
  });
}

fun execWriteCsv(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  source = args.maybeGetString("source") match {
  | Some(src) -> src.toInt()
  | None() -> SKStore.genSym(0)
  };
  SKDB.runSql(options, context ~> {
    user = args.maybeGetString("user");
    myReadLine = () -> {
      buffer = mutable Vector[];
      loop {
        c = getChar();
        if (c == '\n') return String::fromChars(buffer.toArray());
        buffer.push(c);
      }
    };
    SKCSV.replayDiff(context, myReadLine, user, source)
  })
}

fun execSubscribe(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  views = args.getArray("views").map(v -> v.lowercase());
  init = args.getBool("connect");
  SKDB.runLockedSql(options, context ~> {
    SKDB.forbidNow(context);
    cmd = (
      args.maybeGetString("updates"),
      args.maybeGetString("notify"),
    ) match {
    | (Some(_), Some(_)) ->
      print_error("Cannot have both --updates and --notify");
      skipExit(4)
    | (Some(f), _) -> SKStore.NUpdates(f)
    | (_, Some(f)) -> SKStore.NNotify(f)
    | _ -> SKStore.NTail()
    };
    (input, output) = SKDB.getSubsDirs(context);
    viewKey = SKStore.SID(
      views.maybeGet(0).fromSome("Must specify at least one view or table"),
    );
    inputDir = context.unsafeGetEagerDir(input.dirName);
    sessionID = SKStore.genSym(0);
    request = SKDB.SubRequestFile(
      views,
      options.format,
      init,
      cmd,
      sessionID,
      args.maybeGetString("ignore-source").map(x -> x.toInt()),
    );
    inputDir.write(context, viewKey, request);
    context.update();
    outputDir = context.unsafeGetEagerDir(output.dirName);
    file = outputDir.getArrayRaw(viewKey)[0];
    invariant(sessionID == SKStore.IntFile::type(file).value);
    print_string(sessionID.toString());
  })
}

fun execCanMirror(args: Cli.ParseResults, options: SKDB.Options): void {
  ensureContext(args);
  tableName = args.getString("table");
  SKDB.runSql(options, context ~> {
    SKCSV.reasonSchemaUnsupported(context, tableName.lowercase()) match {
    | None() -> void
    | Some(reason) -> print_string(reason)
    };
    SKStore.CStop(None())
  })
}

fun execReplay(_args: Cli.ParseResults, _options: SKDB.Options): void {
  state = SKCSV.replayStdin();
  state.each((value, txNbrAndRepeat) -> {
    (_, repeat) = txNbrAndRepeat;
    for (_ in Range(0, repeat)) {
      print_string(value);
    }
  })
}

fun execToggleView(args: Cli.ParseResults, _options: SKDB.Options): void {
  ensureContext(args);
  tableName = args.getString("table");
  SKDB.runSql(_options, context ~> {
    tables = getTableDir(context);
    baseName = SKStore.SID::create(tableName.lowercase());
    tables.maybeGet(context, baseName) match {
    | None() -> error(0, "Table not found: " + tableName)
    | Some(dirDescr) ->
      tables.writeArray(
        context,
        baseName,
        Array[dirDescr with {view => !dirDescr.view}],
      )
    };
    SKStore.CStop(None())
  })
}

untracked fun execDebug(_args: Cli.ParseResults, _options: SKDB.Options): void {
  SKStore.toplevel(SKStore.Context{});
}
