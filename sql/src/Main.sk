@cpp_extern("SKIP_unix_die_on_EOF")
native fun dieOnEOF(): void;

module SKDB;

/*****************************************************************************/
/* Helpers */
/*****************************************************************************/

@cpp_export("getVersion")
fun getVersion(): String {
  `${SkargoVersion.kVersion} (${SkargoVersion.kCommit})`
}

fun getFieldNames(
  context: readonly SKFS.Context,
  dirName: SKFS.DirName,
): Array<String> {
  mcontext = context.mclone();
  tables = SKSQL.getTableDir(mcontext);
  dirNameStr = dirName.toString();
  iter = dirNameStr.getIter();
  _ = iter.next();
  tableName = dirNameStr.sub(iter, dirNameStr.length() - 2);
  arr = tables.getArray(mcontext, SKFS.SID(tableName));
  if (arr.size() == 0) {
    print_error("There is no sql table associated with dir: " + dirNameStr);
    skipExit(44);
  };
  dirDescr = arr[0];
  dirDescr.schema.map(x -> x.name.origName);
}

fun fixUpDirName(dirNameStr: String): SKFS.DirName {
  chars = dirNameStr.chars();
  SKFS.DirName::create(
    (if (chars[0] != '/') "/" else "") +
      dirNameStr +
      (if (chars[chars.size() - 1] != '/') "/" else ""),
  )
}

/*****************************************************************************/
/* Main */
/*****************************************************************************/

untracked fun main(): void {
  saved = SKFS.newObstack();
  vtry(
    () -> {
      args = Cli.Command("skdb")
        .about(
          "The SQL database that tells you when your query results changed",
        )
        .arg(Cli.StringArg("init").about("Initialize new SKFS runtime data"))
        .arg(
          Cli.StringArg("data")
            .about("Use existing SKFS runtime data")
            .global(),
        )
        .arg(Cli.BoolArg("backtrace").about("Internal use").global())
        .arg(Cli.BoolArg("sync").about("Sync to disk").global())
        .arg(
          Cli.StringArg("format")
            .default("sql")
            .about("Output format (sql, csv, or json)")
            .global(),
        )
        .arg(
          Cli.BoolArg("always-allow-joins")
            .about("Allow cross joins and joins outside of virtual views")
            .global(),
        )
        .arg(
          Cli.BoolArg("show-used-indexes")
            .about("Print indexes used by a query to stdout")
            .global(),
        )
        .arg(
          Cli.StringArg("capacity").about(
            "Initialize SKFS runtime with given capacity",
          ),
        )
        .subcommand(
          Cli.Command("sessions").about("List the current subscriptions"),
        )
        .subcommand(Cli.Command("compact").about("Compact the db"))
        .subcommand(
          Cli.Command("dump-table")
            .about("Print a specific table signature")
            .arg(
              Cli.StringArg("table")
                .positional()
                .required()
                .about("Table name"),
            )
            .arg(Cli.StringArg("table-suffix").about("Optional suffix")),
        )
        .subcommand(
          Cli.Command("dump-tables")
            .about("Dumps the tables in SQL format")
            .arg(Cli.StringArg("table-suffix").about("Optional suffix")),
        )
        .subcommand(
          Cli.Command("dump-inserts").about("Dump the inserts in SQL format"),
        )
        .subcommand(
          Cli.Command("dump-view")
            .about("Print a specific view in SQL format")
            .arg(
              Cli.StringArg("view").positional().required().about("View name"),
            ),
        )
        .subcommand(
          Cli.Command("dump-views").about("Dump the views in SQL format"),
        )
        .subcommand(
          Cli.Command("dump").about("Dumps tables/inserts/views in SQL format"),
        )
        .subcommand(
          Cli.Command("csv-field")
            .about("Output a specific CSV field")
            .arg(
              Cli.StringArg("field")
                .positional()
                .required()
                .about("Field number"),
            ),
        )
        .subcommand(
          Cli.Command("load-csv")
            .about("Load CSV values into table")
            .arg(
              Cli.StringArg("table")
                .positional()
                .required()
                .about("Table name"),
            )
            // TODO: Why is `--user` only offered for CSV variants?
            .arg(Cli.StringArg("user").about("Name of the user")),
        )
        .subcommand(Cli.Command("size").about("Output the size of the db"))
        .subcommand(
          Cli.Command("diff")
            .about("Send the diff from session")
            .arg(
              Cli.StringArg("session-id")
                .positional()
                .required()
                .about("Session id"),
            )
            .arg(
              Cli.StringArg("since")
                .required()
                .about("Starting time of the diff"),
            ),
        )
        .subcommand(
          Cli.Command("disconnect")
            .about("Disconnect a session")
            .arg(
              Cli.StringArg("session-id")
                .positional()
                .required()
                .about("Session id"),
            ),
        )
        .subcommand(
          Cli.Command("write")
            .about("Write data from stdin into a directory")
            .arg(
              Cli.StringArg("directory")
                .positional()
                .required()
                .about("Directory name"),
            ),
        )
        .subcommand(
          Cli.Command("watermark")
            .about("Get the watermark for table TABLE")
            .arg(
              Cli.StringArg("source")
                .required()
                .about("Globally unique identity of this write stream"),
            )
            .arg(
              Cli.StringArg("table")
                .positional()
                .required()
                .about("Table name"),
            ),
        )
        .subcommand(
          Cli.Command("replication-id")
            .about("Get a unique id for CLIENT-UUID")
            .arg(
              Cli.StringArg("client-uuid")
                .positional()
                .required()
                .about("UUID of the client instance"),
            ),
        )
        .subcommand(
          Cli.Command("write-csv")
            .about("Write data from stdin into a directory in CSV format")
            .arg(
              Cli.StringArg("table")
                .positional()
                .required()
                .about("Table name"),
            )
            .arg(
              Cli.StringArg("source").about(
                "Globally unique identity of this write stream",
              ),
            )
            .arg(Cli.StringArg("user").about("Name of the user")),
        )
        .subcommand(
          Cli.Command("tail")
            .about("Tail changes on a directory")
            .arg(
              Cli.StringArg("session-id")
                .positional()
                .required()
                .about("Session id"),
            )
            .arg(
              Cli.StringArg("filter")
                .positional()
                .about("SQL filter condition"),
            )
            .arg(
              Cli.BoolArg("follow")
                .long("follow")
                .short("f")
                .about("Output appended data as the database grows"),
            )
            .arg(
              Cli.StringArg("since")
                .long("since")
                .about("Starting time of the tail"),
            ),
        )
        // TODO: Merge both subscribe and connect (add a boolean option to subscribe.
        .subcommand(
          Cli.Command("subscribe")
            .about("Subscribe to a directory change")
            .arg(
              Cli.StringArg("view").positional().required().about("View name"),
            )
            .arg(Cli.BoolArg("connect").about("Send the initial state first"))
            .arg(
              Cli.StringArg("updates").about(
                "Name of the file where the updates will be written",
              ),
            )
            .arg(
              Cli.StringArg("notify").about(
                "Name of the file updates with time of the last change",
              ),
            )
            .arg(Cli.StringArg("user").about("Name of the user"))
            .arg(
              Cli.StringArg("ignore-source").about("Write stream to ignore"),
            ),
        )
        .subcommand(
          Cli.Command("can-mirror")
            .about("Check that a table is eligible for mirroring")
            .arg(
              Cli.StringArg("table")
                .positional()
                .required()
                .about("Table name"),
            ),
        )
        .subcommand(Cli.Command("replay").about("Replay a diff"))
        .subcommand(Cli.Command("debug").about("TODO"))
        .help()
        .parseArgs();

      options = SKSQL.Options{
        backtrace => args.getBool("backtrace"),
        alwaysAllowJoins => args.getBool("always-allow-joins"),
        sync => args.getBool("sync"),
        showUsedIndexes => args.getBool("show-used-indexes"),
        format => args.getString("format") match {
        | "csv" -> SKSQL.OFK_CSV()
        | "json" -> SKSQL.OFK_JSON()
        | "sql" -> SKSQL.OFK_SQL()
        | "js" -> SKSQL.OFK_JS()
        | f -> invariant_violation(`Unsupported format: ${f}`)
        },
      };

      subcmd_handler = args.subcommand
        .map(subcmd ->
          subcmd match {
          | "sessions" -> execSessions
          | "compact" -> execCompact
          | "dump-table" -> execDumpTable
          | "dump-tables" -> execDumpTables
          | "dump-inserts" -> execDumpInserts
          | "dump-view" -> execDumpView
          | "dump-views" -> execDumpViews
          | "dump" -> execDump
          | "load-csv" -> execLoadCsv
          | "csv-field" -> execCsvField
          | "size" -> execSize
          | "diff" -> execDiff
          | "disconnect" -> execDisconnect
          | "write" -> execWrite
          | "tail" -> execTail
          | "watermark" -> execWatermark
          | "replication-id" -> execReplicationId
          | "write-csv" -> execWriteCsv
          | "subscribe" -> execSubscribe
          | "can-mirror" -> execCanMirror
          | "replay" -> execReplay
          | "debug" -> execDebug
          | _ -> invariant_violation(`Unknown subcommand ${subcmd}`)
          }
        )
        .default((args, options) -> {
          // NOTE: This should be a subcommand, but the `--init` flag is currently
          // hardcoded in the runtime. It should be revisited once the runtime has
          // a proper two-step init API for persistence.
          if (args.maybeGetString("init") is Some _) {
            _ = SKFS.gContextInit(SKSQL.makeSqlContext().clone());
            return void
          } else if (args.maybeGetString("capacity") is Some _) {
            print_error("cannot use capacity without init");
            skipExit(2)
          };
          // TODO: If `--user` is actually needed, reinstate it. It was clashing with
          // other options and was removed for convenience.
          // user = argMap.maybeGet("user") match {
          //   | Some(AP.StringValue{value => userName}) -> Some(userName)
          //   | _ -> None()
          //   };
          SKSQL.eval(options, /* user = */ None())
        });
      subcmd_handler(args, options);
    },
    exn -> {
      SKFS.destroyObstack(saved);
      throw exn;
    },
  );
  SKFS.destroyObstack(saved);
}

private fun ensureContext(args: Cli.ParseResults): void {
  if (SKFS.gHasContext() == 0) {
    invariant(args.maybeGetString("data") is None _);
    print_error("Error: option --data is missing");
    skipExit(2);
  };
}

fun execSessions(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  SKSQL.runSql(options, context ~> {
    for (id => sub in context.sessions) {
      dirName = sub.dirName;
      print_string(id.toString() + "\t" + dirName.toString());
    };
    SKFS.CStop(None())
  })
}

fun execCompact(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  SKSQL.runLockedSql(options, context ~> {
    for (_dirName => dir in context.dirs.state) {
      dir match {
      | edir @ SKFS.EagerDir _ ->
        !edir = edir.purge(context);
        context.setDir(edir.dirName, edir)
      | _ -> void
      }
    }
  })
}

fun execDumpTable(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  tableName = args.getString("table");
  suffix = args.maybeGetString("table-suffix");
  SKSQL.runSql(options, context ~> {
    SKSQL.dumpTable(context, tableName.lowercase(), suffix);
    SKFS.CStop(None())
  })
}

fun execDumpTables(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  suffix = args.maybeGetString("table-suffix");
  SKSQL.runSql(options, context ~> {
    SKSQL.dumpTables(options, context, suffix);
    SKFS.CStop(None())
  })
}

fun execDumpInserts(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  SKSQL.runSql(options, context ~> {
    SKSQL.dumpInserts(context);
    SKFS.CStop(None())
  })
}

fun execDumpView(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  viewName = args.getString("view");
  SKSQL.runSql(options, context ~> {
    SKSQL.dumpView(context, viewName.lowercase());
    SKFS.CStop(None())
  })
}

fun execDumpViews(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  SKSQL.runSql(options, context ~> {
    SKSQL.dumpViews(options, context);
    SKFS.CStop(None())
  })
}

fun execDump(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  SKSQL.runSql(options, context ~> {
    SKSQL.dumpTables(options, context, None());
    SKSQL.dumpInserts(context);
    SKSQL.dumpViews(options, context);
    SKFS.CStop(None())
  })
}

fun execLoadCsv(args: Cli.ParseResults, options: SKSQL.Options): void {
  tableNameUpper = args.getString("table");
  tableName = tableNameUpper.lowercase();
  name = SKFS.SID::create(tableName);
  SKSQL.runSql(options, context ~> {
    table = context.getGlobal("CSV_TABLE") match {
    | None() ->
      tableDescr = SKSQL.getTable(options, context, 0, name);
      context.setGlobal("CSV_TABLE", tableDescr);
      tableDescr
    | Some(x) -> SKSQL.DirDescr::fromFile(x)
    };
    line = context.getGlobal("Line") match {
    | None() -> mutable Ref(1)
    | Some(file) -> mutable Ref(SKFS.IntFile::fromFile(file).value)
    };
    user = args.maybeGetString("user") match {
    | None() -> None()
    | Some(userName) -> Some(SKSQL.UserFile::create(context, userName))
    };
    vtry<SKFS.ContextOp>(
      () -> {
        contextOp = SKCSV.insert(context, line, options, table, user);
        context.setGlobal("Line", SKFS.IntFile(line.get()));
        contextOp
      },
      exn -> {
        print_error("Error, line " + line.get() + ": " + exn.getMessage());
        skipExit(23);
      },
    );
  })
}

fun execCsvField(args: Cli.ParseResults, _options: SKSQL.Options): void {
  fieldNbr = args.getString("field").toInt();
  line = mutable Ref(1);
  loop {
    (eof, rows) = SKCSV.parseCsv(line, x ~> x);
    for (row in rows) {
      if (fieldNbr < 0 || fieldNbr >= row.size()) continue;
      str = row[fieldNbr].i1;
      print_string(str);
    };
    if (eof) return void;
  }
}

fun execSize(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  SKSQL.runSql(options, _context ~> {
    SKFS.printPersistentSize();
    SKFS.CStop(None())
  })
}

fun execDiff(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  sessionID = args.getString("session-id").toInt();
  time = args.getString("since").toInt();
  SKSQL.runSql(options, origContext ~> {
    context = origContext.mclone();
    sub = context.sessions.maybeGet(sessionID) match {
    | None() ->
      print_error("Error: session not found");
      skipExit(2)
    | Some(x) -> x
    };
    format = options.format match {
    | SKSQL.OFK_CSV() -> SKFS.OCSV()
    | SKSQL.OFK_JSON() -> SKFS.OJSON(getFieldNames(context, sub.dirName))
    | SKSQL.OFK_SQL() -> SKFS.OSQL()
    | SKSQL.OFK_JS() -> SKFS.OJS(getFieldNames(context, sub.dirName))
    };

    origContext.setGlobal(
      "Stdout",
      SKSQL.StdoutDiff(
        format,
        sub.dirName,
        SKFS.Tick(time),
        sub.filter,
        sub.getDestinationWatermark,
      ),
    );
    SKFS.CStop(None())
  })
}

fun execDisconnect(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  sessionID = args.getString("session-id").toInt();
  SKSQL.runLockedSql(options, context ~> {
    context.sessions.maybeGet(sessionID) match {
    | None() ->
      print_error("Error: session not found");
      skipExit(2)
    | Some(_) -> context.!sessions = context.sessions.remove(sessionID)
    };
  })
}

fun execWrite(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  dirNameStr = args.getString("directory");
  SKSQL.runSql(options, context ~> {
    SKFS.writeFromStdin(context, dirNameStr);
    SKFS.CStop(None())
  })
}

fun execTail(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  sessionID = args.getString("session-id").toInt();
  followMode = args.getBool("follow");
  tick = args.maybeGetString("since") match {
  | Some(since) -> since.toInt()
  | _ -> 0
  };
  init = true;
  dieOnEOF();

  gContext = SKFS.gContextGet();
  (subFilter, dirName) = gContext.sessions.maybeGet(sessionID) match {
  | None() ->
    print_error("Error: session not found");
    skipExit(2)
  | Some(sub) -> (sub.filter, sub.dirName)
  };

  filter = args.maybeGetString("filter") match {
  | None() -> subFilter
  | Some(strCond) ->
    tableName = dirName.toString().stripPrefix("/").stripSuffix("/");
    from = Some(
      Array[
        SKSQL.TableName(SKSQL.FName(SKSQL.Name::create(tableName)), None()),
      ],
    );
    compiler = SKSQL.Compiler::create(false, options, 0);
    (_, ast) = SKSQL.parseExpr(SKSQL.Lexer(0, SKSQL.Buffer(strCond)), 0);
    compilerContext = gContext.mclone();
    _ = compiler.compileFrom(compilerContext, from);
    e = compiler.compileExpr(compilerContext, ast) match {
    | SKSQL.CIExpr(x) -> x
    | _ ->
      print_error("Unexpected type for filter expression");
      skipExit(2)
    };
    (context, isReset) ~> {
      mcontext = context.mclone();
      privacyFilter = subFilter(context, isReset);
      baseName -> {
        inputRow = baseName match {
        | SKSQL.RowKey(row, _) -> row
        | _ ->
          print_error("Unexpected table entry type");
          skipExit(2)
        };
        evaluator = SKSQL.ExprEvaluator(
          None(),
          Array[inputRow],
          Array[],
          None(),
        );

        evaluator.evalCIExpr(mcontext, e) match {
        | SKSQL.ANull()
        | SKSQL.ADef(0) ->
          false
        | SKSQL.AUndef()
        | SKSQL.ADef(_) ->
          privacyFilter(baseName)
        };
      }
    }
  };

  loop {
    localObstack = SKFS.newObstack();
    context = SKFS.gContextGet();
    sub = context.sessions.maybeGet(sessionID) match {
    | None() ->
      print_error("Error: session not found");
      skipExit(2)
    | Some(x) -> x
    };
    invariant(dirName == sub.dirName);
    edir = context.unsafeGetEagerDir(dirName);
    format = options.format match {
    | SKSQL.OFK_CSV() -> SKFS.OCSV()
    | SKSQL.OFK_JSON() -> SKFS.OJSON(getFieldNames(context, dirName))
    | SKSQL.OFK_SQL() -> SKFS.OSQL()
    | SKSQL.OFK_JS() -> SKFS.OJS(getFieldNames(context, dirName))
    };

    sub.userID match {
    | Some(userID) if (sub.reset(context, SKFS.Tick(tick)) && !init) ->
      readers = context.unsafeGetEagerDir(
        SKFS.DirName::create("/skdb_access_readers/"),
      );
      toAdd = mutable Set[];
      toRemove = mutable Set[];
      // isReset can be ignored, because whenever it's true, it just
      // makes us do more work than necessary.
      (_isReset, items) = readers.getChangesAfter(SKFS.Tick(tick));
      for (rowKey in items) {
        rowKey match {
        | SKSQL.RowKey(row, _) ->
          if (row.getInt(1).fromSome() == userID) {
            arr = readers.getArrayRaw(rowKey);
            groupID = row.getInt(0).fromSome();
            if (groupID > 0) { // Dealing with a whitelist
              if (arr.isEmpty()) {
                toRemove.insert(groupID);
              } else {
                toAdd.insert(groupID);
              }
            } else { // Dealing with a blacklist
              if (arr.isEmpty()) {
                toAdd.insert(groupID);
              } else {
                toRemove.insert(groupID);
              }
            }
          }
        | _ -> invariant_violation("Unexpected key type")
        }
      };
      writer = mutable Debug.BufferedWriter(print_raw, 1024);
      writer.write("\n");
      writer.write("\n");
      for (kv in edir.unsafeGetFileIter()) {
        (key, valueIter) = kv;
        values = valueIter.collect(Array);
        if (toAdd.contains(sub.getGroupID(key))) {
          if (values.size() == 0) {
            writer.write(key.toKVStringRemove(format))
          } else {
            for (value in values) {
              writer.write(value.toKVString(format, key))
            }
          }
        } else if (toRemove.contains(sub.getGroupID(key))) {
          key match {
          | SKSQL.RowKey(row, _) ->
            writer.write(row.setRepeat(0).toKVString(format, key))
          | _ -> void
          }
        }
      };
      writer.flush();
      flushStdout()
    | _ -> void
    };
    (isReset, changes) = edir.getChangesAfter(SKFS.Tick(tick));

    producedOutput = edir.writeDiffStdout(
      context,
      isReset,
      changes,
      print_raw,
      format,
      filter,
      sub.getDestinationWatermark(context),
    );
    if (!producedOutput && init) {
      // on first iteration we ensure we output a checkpoint without
      // delay so that the downstreams knows that it has received
      // everything without waiting for the condvar timeout
      print_raw(":" + tick.toString() + "\n");
      flushStdout();
    };
    !tick = context.tick.value;
    !init = false;
    lock = SKFS.unfreezeLock(sub.lock);
    cond = SKFS.unfreezeCond(sub.cond);
    SKFS.mutexLock(lock);
    while ({
      newContext = SKFS.gContextGet();
      followMode &&
        {
          (newIsReset, newChanges) = newContext
            .unsafeGetEagerDir(dirName)
            .getChangesAfter(SKFS.Tick(tick));
          !newIsReset && newChanges.isEmpty()
        } &&
        {
          (newIsReset, newChanges) = newContext
            .unsafeGetEagerDir(SKFS.accessReaders)
            .getChangesAfter(SKFS.Tick(tick));
          !newIsReset && newChanges.isEmpty()
        }
    }) {
      timeoutSecs = 10;
      _ = SKFS.condTimedWait(cond, lock, UInt32::truncate(timeoutSecs));
      print_raw(":" + tick.toString() + "\n");
      flushStdout();
    };
    SKFS.mutexUnlock(lock);
    SKFS.destroyObstack(localObstack);
    if (!followMode) {
      break void
    }
  }
}

fun execWatermark(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  tableName = args.getString("table").lowercase();
  source = args.getString("source").toIntOption();
  SKSQL.runSql(options, context ~> {
    print_string(
      SKSQL.getWatermark(context.clone(), tableName, source).default(
        SKFS.Tick(0),
      ).value,
    );
    SKFS.CStop(None())
  });
}

fun execReplicationId(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  clientUuid = args.getString("client-uuid").lowercase();
  SKSQL.runSql(options, context ~> {
    clientsDirname = SKFS.DirName::create(`/clients/`);
    clientsDir = context.maybeGetDir(clientsDirname) match {
    | None() -> context.mkdir(SKFS.IntFile::fromFile, clientsDirname, false)
    | Some(d) -> SKFS.EHandle(SKFS.IntFile::fromFile, d.getDirName())
    };
    key = SKFS.SID::create(clientUuid);
    arr = clientsDir.unsafeGetArray(context, key);
    replicationSource = if (arr.size() > 0) {
      arr[0].value
    } else {
      source = SKFS.genSym(0);
      clientsDir.writeArray(context, key, Array[SKFS.IntFile(source)]);
      source
    };
    print_string(replicationSource);
    SKFS.CStop(None())
  });
}

fun execWriteCsv(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  tableName = args.getString("table").lowercase();
  name = SKFS.SID::create(tableName);
  SKSQL.runSql(options, context ~> {
    table = context.getGlobal("CSV_TABLE") match {
    | None() ->
      tableDescr = SKSQL.getTable(options, context, 0, name);
      context.setGlobal("CSV_TABLE", tableDescr);
      tableDescr
    | Some(x) -> SKSQL.DirDescr::fromFile(x)
    };
    line = context.getGlobal("Line") match {
    | None() -> mutable Ref(1)
    | Some(file) -> mutable Ref(SKFS.IntFile::fromFile(file).value)
    };
    user = args.maybeGetString("user");
    myReadLine = () -> {
      buffer = mutable Vector[];
      loop {
        c = getChar();
        if (c == '\n') return String::fromChars(buffer.toArray());
        buffer.push(c);
      }
    };
    source = args.maybeGetString("source") match {
    | Some(src) -> src.toInt()
    | None() -> SKFS.genSym(0)
    };
    SKCSV.replayDiff(context, line, myReadLine, table, user, source)
  })
}

fun execSubscribe(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  userViewName = args.getString("view").lowercase();
  viewDirName = fixUpDirName(userViewName);
  init = args.getBool("connect");
  SKSQL.runLockedSql(options, context ~> {
    viewName = userViewName.lowercase();
    SKSQL.forbidNow(context);
    format = options.format match {
    | SKSQL.OFK_CSV() -> SKFS.OCSV()
    | SKSQL.OFK_JSON() -> SKFS.OJSON(getFieldNames(context, viewDirName))
    | SKSQL.OFK_SQL() -> SKFS.OSQL()
    | SKSQL.OFK_JS() -> SKFS.OJS(getFieldNames(context, viewDirName))
    };
    cmd = (
      args.maybeGetString("updates"),
      args.maybeGetString("notify"),
    ) match {
    | (Some(_), Some(_)) ->
      print_error("Cannot have both --updates and --notify");
      skipExit(4)
    | (Some(x), _) -> SKFS.NUpdates(format, x)
    | (_, Some(x)) -> SKFS.NNotify(x)
    | _ -> SKFS.NTail()
    };
    (input, output) = SKSQL.getSubsDirs(options, context);
    viewKey = SKFS.SID(viewName);
    inputDir = context.unsafeGetEagerDir(input.dirName);
    sessionID = SKFS.genSym(0);
    request = SKSQL.SubRequestFile(
      viewName,
      viewDirName,
      init,
      cmd,
      sessionID,
      args.maybeGetString("user"),
      args.maybeGetString("ignore-source").map(x -> x.toInt()),
    );
    inputDir.write(context, viewKey, request);
    context.update();
    outputDir = context.unsafeGetEagerDir(output.dirName);
    file = outputDir.getArrayRaw(viewKey)[0];
    invariant(sessionID == SKFS.IntFile::fromFile(file).value);
    print_string(sessionID.toString());
  })
}

fun execCanMirror(args: Cli.ParseResults, options: SKSQL.Options): void {
  ensureContext(args);
  tableName = args.getString("table");
  SKSQL.runSql(options, context ~> {
    SKCSV.reasonSchemaUnsupported(context, tableName.lowercase()) match {
    | None() -> void
    | Some(reason) -> print_string(reason)
    };
    SKFS.CStop(None())
  })
}

fun execReplay(_args: Cli.ParseResults, _options: SKSQL.Options): void {
  state = SKCSV.replayStdin();
  state.each((value, txNbrAndRepeat) -> {
    (_, repeat) = txNbrAndRepeat;
    for (_ in Range(0, repeat)) {
      print_string(value);
    }
  })
}

untracked fun execDebug(
  _args: Cli.ParseResults,
  _options: SKSQL.Options,
): void {
  SKFS.toplevel(SKFS.Context{});
}
