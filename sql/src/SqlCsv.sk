module alias P = SQLParser;

module SKCSV;

base class Token {
  children =
  | NewLine()
  | Comma()
  | Chars(Array<Char>)
}

fun lexRaw(next: () -> Char): mutable Iterator<Token> {
  acc = mutable Vector[];
  lastIsString = false;
  loop {
    next() match {
    | '\n' ->
      if (!lastIsString) {
        str = acc.toArray();
        acc.clear();
        yield Chars(str);
      };
      break void
    | ',' ->
      if (!lastIsString) {
        str = acc.toArray();
        acc.clear();
        yield Chars(str);
      };
      !lastIsString = false;

      yield Comma()
    | '"' ->
      !lastIsString = true;
      acc.push('"');
      loop {
        c = next();
        acc.push(c);
        if (c == '"') {
          break void;
        }
      };
      str = acc.toArray();
      acc.clear();
      yield Chars(str)
    | x ->
      !lastIsString = false;
      acc.push(x)
    }
  }
}

base class CValue {
  children =
  | CInt(Int)
  | CFloat(Float)
  | CString(String)
}

fun trim(chars: Array<Char>): Array<Char> {
  i = 0;
  while (i < chars.size() && chars[i] == ' ') !i = i + 1;
  j = chars.size();
  while (j - 1 >= 0 && chars[j - 1] == ' ') !j = j - 1;
  chars.slice(i, j)
}

fun lex(next: () -> Char): mutable Iterator<(Bool, String)> {
  stringAcc: ?mutable Vector<Char> = None();
  isString: Bool = false;
  for (tok in lexRaw(next)) {
    (tok, stringAcc) match {
    | (Chars(chars), Some(acc)) if (chars.size() > 0 && chars[0] == '"') ->
      !isString = true;
      !chars = trim(chars);
      acc.extend(chars.slice(0, chars.size() - 1))
    | (
      Chars(chars),
      None(),
    ) if (chars.size() > 0 && chars[chars.size() - 1] == '"') ->
      !isString = true;
      !chars = trim(chars);
      !chars = chars.slice(1, chars.size() - 1);
      !stringAcc = Some(Vector::mcreateFromItems(chars))
    | _ ->
      stringAcc match {
      | None() -> void
      | Some(acc) ->
        !stringAcc = None();
        yield (isString, String::fromChars(acc.toArray()))
      };
      !isString = false;
      tok match {
      | Chars(chars) -> yield (false, String::fromChars(trim(chars)))
      | NewLine() -> break void
      | Comma() -> void
      }
    }
  };
  stringAcc match {
  | None() -> void
  | Some(acc) ->
    !stringAcc = None();
    yield (isString, String::fromChars(acc.toArray()))
  }
}

fun parseCsv<T>(
  line: mutable Ref<Int>,
  f: ((Bool, String)) ~> T,
): (Bool, Array<Array<T>>) {
  array = mutable Vector[];
  eof = false;
  try {
    for (_ in Range(0, 1000)) {
      values = mutable Vector[];
      for (value in lex(() -> getChar())) {
        values.push(value);
      };
      cvalues = values.map(f);
      array.push(cvalues.toArray());
      line.set(line.get() + 1);
    }
  } catch {
  | EndOfFile _ ->
    !eof = true;
    void
  | exn ->
    print_error("Error, line " + line.get() + ": " + exn.getMessage());
    skipExit(23)
  };
  (eof, array.toArray())
}

fun parseCSVValue(kv: (Bool, String)): P.Value {
  (isStr, str) = kv;
  if (isStr) return P.VString(str);
  if (str == "") return P.VNull();
  str.toIntOption() match {
  | None() ->
    str.toFloatOption() match {
    | None() -> P.VString(str)
    | Some(f) -> P.VFloat(f)
    }
  | Some(x) -> P.VInt(x)
  }
}

fun insert(
  context: mutable SKStore.Context,
  line: mutable Ref<Int>,
  options: SKDB.Options,
  table: SKDB.DirDescr,
  user: ?SKDB.UserFile,
): SKStore.ContextOp {
  // empty params since no placeholders in input to skdb load-csv
  params: Map<String, P.Value> = Map[];
  eval = SKDB.Evaluator{options, user};
  pos = 0;
  inTransaction = false;
  paramsOpt = None();
  (eof, array) = parseCsv(line, parseCSVValue);
  f = eval.insert(
    context,
    params,
    pos,
    None(),
    inTransaction,
    table,
    paramsOpt,
    array,
  );
  if (!eof) return SKStore.CContinue(f);
  SKStore.CStop(f)
}

fun reasonSchemaUnsupported(
  origContext: readonly SKStore.Context,
  tableName: String,
  schema: String,
): ?String {
  context = SKStore.Context::fromSaved(origContext.clone());
  SKDB.getTableDir(context).maybeGet(context, SKStore.SID(tableName)) match {
  | None() -> Some(`Table '${tableName}' does not exist.`)
  | Some(dirDescr) ->
    if (dirDescr.schema.any(x ~> x.unique is Some _)) {
      return Some("Cannot mirror tables with unique constraints.")
    };
    dirDescr.cols.maybeGet(SKDB.skdbAccessColName) match {
    | Some _ -> void
    | None() ->
      return Some(
        `Cannot mirror tables without ${
          SKDB.skdbAccessColName.origName
        } column.`,
      )
    };

    if (schema != "*") {
      try {
        Some(P.Parser::create(schema).parseCreateTableSchema().columns)
      } catch {
      | _exn -> None()
      } match {
      | None() ->
        return Some(
          "Malformed schema: expects parenthesized column-separated list of column definitions.",
        )
      | Some(requestSchema) ->
        if (
          requestSchema.size() != dirDescr.schema.size() ||
          requestSchema.zip(dirDescr.schema).any(cols ~> cols.i0 != cols.i1)
        ) {
          return Some(
            "Cannot mirror table: provided schema does not match database.",
          )
        }
      }
    };
    None()
  };
}

fun lwwEdits(
  table: SKDB.DirDescr,
  snapshot: Int,
  writer: SKStore.Path,
  primaryIdxOpt: ?Int,
  context: readonly SKStore.Context,
  dir: SKStore.EagerDir,
  row: SKDB.RowValues,
): mutable Iterator<
  (SKStore.Key, (SKStore.Path, SKStore.Path, Array<SKStore.File>)),
> {
  mcontext = context.mclone();
  primaryIdx = primaryIdxOpt match {
  | None() -> invariant_violation("Using LWW without a primary key.")
  | Some(p) -> p
  };
  indexEntry = SKDB.makeIndexEntry(table.name, primaryIdx);
  indexTable = SKDB.getIndexByColNbr(mcontext);
  indexes = indexTable.unsafeGetArray(mcontext, indexEntry);
  invariant(indexes.size() > 0);
  index = indexes[0];
  indexDir = mcontext.unsafeGetEagerDir(index.dirName);
  primaryKey = row.getValue(primaryIdx);
  startKey = SKDB.RowKey::create(
    SKDB.RowValues::create(Array[primaryKey], 1),
    index.fields,
  );
  entries = mutable Vector[];

  keepingCurrent = false;
  iter = indexDir.unsafeGetFileIter(Some(startKey));
  loop {
    (key, valueIter) = iter.next() match {
    | None() -> break void
    | Some(x) -> x
    };
    rowKey = SKDB.RowKey::keyType(key);
    valueIter.next() match {
    | None() -> continue
    | _ -> void
    };
    if (rowKey.row.getValue(0) != primaryKey) break void;

    for ((tick, source, _) in dir.getDataIterWithoutTombs(mcontext, key)) {
      if (
        tick.value < snapshot ||
        source.path() == writer ||
        rowKey.row < row
      ) {
        entries.push((key, (source.path(), writer, Array<SKStore.File>[])));
      } else {
        !keepingCurrent = true;
        break void;
      }
    }
  };

  if (!keepingCurrent) {
    for (entry in entries) yield entry;
    yield (
      SKDB.RowKey(row, table.kinds),
      (writer, writer, Array<SKStore.File>[row]),
    );
  }
}

fun applyDiffStrategy(
  table: SKDB.DirDescr,
  identity: Int,
  userFileOpt: ?SKDB.UserFile,
  reset: Bool,
  rows: Array<SKDB.RowValues>,
  checkpoint: ?Int,
  snapshot: ?Int,
): ?((
  mutable SKStore.Context,
  mutable SKStore.Context,
  SKStore.Context,
) ~> void) {
  writer = SKStore.Path(table.dirName, SKStore.IID(identity));

  shouldShortCircuitUpdate = (context) ~> {
    previouslySeen = SKDB.getWatermark(
      context,
      table.name.lower,
      Some(identity),
    );
    (checkpoint, previouslySeen) match {
    | (Some(x), Some(y)) if (x <= y.value) -> true
    | _ -> false
    };
  };

  checkpointAndAck = (context, delta) ~> {
    checkpoint match {
    // we do not checkpoint 0. this value communicates that you
    // haven't received a full snapshot yet. it's used for e.g.
    // chunking an initial mirror. once the value is > 0 we have
    // received a consistent snapshot of the server and should
    // checkpoint and ack.
    | Some(val) if (val > 0) ->
      checkpointTick = SKStore.Tick(val);
      SKDB.setWatermark(context, table.name.lower, identity, checkpointTick);
      delta.setGlobal(
        "Ack",
        SKDB.StdoutCheckpointAck(
          table.name.origName,
          checkpointTick,
          delta.getGlobal("Ack").map(SKDB.StdoutCheckpointAck::type),
        ),
      )
    | _ -> void
    }
  };

  primaryIdx = for ((i, type) in table.schema.items()) {
    if (type.primary is Some _) {
      break Some(i)
    }
  } else {
    None()
  };

  isVisibleToUser = (context) ~> {
    userFileOpt match {
    | None() -> _ -> true
    | Some(userFile) ->
      (file: SKStore.Key) -> {
        file match {
        | k @ SKDB.RowKey _ ->
          SKDB.checkUserCanReadRow(context, userFile, table, k.row) match {
          | SKDB.AROK() -> true
          | SKDB.ARError(_err) -> false
          }
        | _ -> false
        }
      }
    }
  };

  // we have several update strategies:

  // assignRows - if there are no constraints on the table then we
  // treat the relations as a multiset CRDT. inserts beat deletes when
  // concurrent.
  assignRows = Some((newRoot, delta, root) ~> {
    if (shouldShortCircuitUpdate(root)) {
      return void;
    };

    dir = newRoot.unsafeGetEagerDir(table.dirName);

    !dir = SKStore.withRegionFoldRec(
      Some(newRoot),
      rows.iterator(),
      dir,
      (optContext, row, newDir) ~> {
        ctx = optContext.fromSome();
        key: SKStore.Key = SKDB.RowKey(row.setRepeat(1), table.kinds);
        for ((tick, source, _) in newDir.unsafeGetDataIterWithoutTombs(key)) {
          if (tick.value < snapshot.default(0) || source.path() == writer) {
            !newDir = newDir.writeEntry(
              ctx,
              source.path(),
              writer,
              key,
              Array<SKStore.File>[],
            );
          }
        };

        if (row.repeat > 0) {
          !newDir = newDir.writeEntry(
            ctx,
            writer,
            writer,
            SKDB.RowKey(row, table.kinds),
            Array[row],
          );
        };

        // update incrementally to keep memory usage down. this has a
        // significant effect for large write sets and negligible
        // impact on performance
        ctx.setDir(newDir.dirName, newDir);
        ctx.update();

        newDir
      },
    );

    newRoot.setDir(dir.dirName, dir);
    newRoot.update();
    checkpointAndAck(newRoot, delta)
  });

  // resetRows - if the update is communicating the entire current
  // state (a reset).
  resetRows = Some((newRoot, delta, root) ~> {
    if (shouldShortCircuitUpdate(root)) {
      return void;
    };

    dir = newRoot.unsafeGetEagerDir(table.dirName);

    // we may only affect rows that have been seen
    isEligibleForTomb = (tick, source) ~>
      tick.value < snapshot.default(0) || source.path() == writer;

    !dir = SKStore.withRegionFold(
      Some(newRoot),
      rows.iterator(),
      dir,
      (optContext, row, newDir) ~> {
        key: SKStore.Key = SKDB.RowKey(row, table.kinds);
        keyRepeat = row.repeat;
        for ((tick, source, files) in newDir.unsafeGetDataIterWithoutTombs(
          key,
        )) {
          if (!isEligibleForTomb(tick, source)) {
            continue
          };
          srcRepeat = 0;
          for (file in files) {
            !srcRepeat = srcRepeat + SKDB.RowValues::type(file).repeat
          };

          if (keyRepeat - srcRepeat < 0) {
            !newDir = newDir.writeEntry(
              optContext.fromSome(),
              source.path(),
              writer,
              key,
              Array[],
            );
          } else {
            !keyRepeat = keyRepeat - srcRepeat;
          }
        };

        if (keyRepeat != 0) {
          !newDir = newDir.writeEntry(
            optContext.fromSome(),
            writer,
            writer,
            key,
            Array[row.setRepeat(keyRepeat)],
          );
        };
        newDir
      },
    );

    !dir = dir.reset(
      newRoot,
      writer,
      rows
        .iterator()
        .filter(row -> row.repeat != 0)
        .map(x -> SKDB.RowKey(x.setRepeat(1), table.kinds))
        .collect(SortedSet),
      isVisibleToUser(newRoot),
      isEligibleForTomb,
    );

    newRoot.setDir(dir.dirName, dir);
    newRoot.update();
    checkpointAndAck(newRoot, delta)
  });

  // lwwRows - if there is a unique constraint on the table (e.g. a
  // PK) then we resolve this using LWW. the total order is formed
  // using the vector clock. concurrent tiebreaks use the row data.
  lwwRows = Some((newRoot, delta, root) ~> {
    if (shouldShortCircuitUpdate(root)) {
      return void;
    };

    dir = newRoot.unsafeGetEagerDir(table.dirName);

    !dir = SKStore.withRegionFoldRec(
      Some(newRoot),
      rows.iterator(),
      dir,
      (optContext, row, newDir) ~> {
        ctx = optContext.fromSome();
        if (row.repeat < 1) {
          key: SKStore.Key = SKDB.RowKey(row.setRepeat(1), table.kinds);
          for ((tick, source, _) in newDir.unsafeGetDataIterWithoutTombs(key)) {
            if (tick.value < snapshot.default(0) || source.path() == writer) {
              !newDir = newDir.writeEntry(
                ctx,
                source.path(),
                writer,
                key,
                Array[],
              );
            }
          };
        } else {
          for (edit in lwwEdits(
            table,
            snapshot.default(0),
            writer,
            primaryIdx,
            ctx,
            newDir,
            row,
          )) {
            (editKey, (editSrc, editWriter, editFiles)) = edit;
            !newDir = newDir.writeEntry(
              ctx,
              editSrc,
              editWriter,
              editKey,
              editFiles,
            );
          };
        };

        // update incrementally to keep memory usage down. this has a
        // significant effect for large write sets and negligible
        // impact on performance
        ctx.setDir(newDir.dirName, newDir);
        ctx.update();

        newDir
      },
    );

    newRoot.setDir(dir.dirName, dir);
    newRoot.update();
    checkpointAndAck(newRoot, delta)
  });

  // lwwReset - if the update is communicating the entire current
  // state (a reset) on a table where we use LWW.
  lwwReset = Some((newRoot, delta, root) ~> {
    if (shouldShortCircuitUpdate(root)) {
      return void;
    };

    dir = newRoot.unsafeGetEagerDir(table.dirName);

    !dir = SKStore.withRegionFold(
      Some(newRoot),
      rows.iterator(),
      dir,
      (optContext, row, newDir) ~> {
        if (row.repeat > 0) {
          for (edit in lwwEdits(
            table,
            snapshot.default(0),
            writer,
            primaryIdx,
            optContext.fromSome(),
            newDir,
            row,
          )) {
            (editKey, (editSrc, editWriter, editFiles)) = edit;
            !newDir = newDir.writeEntry(
              optContext.fromSome(),
              editSrc,
              editWriter,
              editKey,
              editFiles,
            );
          };
        };
        newDir
      },
    );

    !dir = dir.reset(
      newRoot,
      writer,
      rows
        .iterator()
        .filter(row -> row.repeat != 0)
        .map(x -> SKDB.RowKey(x.setRepeat(1), table.kinds))
        .collect(SortedSet),
      isVisibleToUser(newRoot),
      (tick, source) ~>
        tick.value < snapshot.default(0) || source.path() == writer
      ,
    );

    newRoot.setDir(dir.dirName, dir);
    newRoot.update();
    checkpointAndAck(newRoot, delta)
  });

  if (primaryIdx is Some _) {
    if (reset) return lwwReset;
    return lwwRows;
  };

  if (reset) return resetRows;

  assignRows
}

fun parseHeader(
  context: mutable SKStore.Context,
  line: String,
): (SKDB.DirDescr, ?Int) {
  if (!line.startsWith("^")) {
    invariant_violation("Not a header")
  };

  tableAndSnapshot = line.stripPrefix("^").split(" ", 2);
  table = tableAndSnapshot.maybeGet(0) match {
  | None() -> invariant_violation("no table found")
  | Some(t) -> SKDB.getTable(context, 0, P.Name::create(t))
  };

  (table, tableAndSnapshot.maybeGet(1).map(x -> x.toInt()))
}

fun parseCheckpoint(line: String): Int {
  if (!line.startsWith(":")) {
    invariant_violation("Not a checkpoint")
  };

  line.stripPrefix(":").toInt()
}

fun parseTableChange(
  context: SKStore.Context,
  table: SKDB.DirDescr,
  line: String,
): Array<SKDB.RowValues> {
  SKStore.withRegionValue(() ~> {
    if (line.startsWith("^") || line.startsWith(":") || line.startsWith("\t")) {
      invariant_violation("Not a table change")
    };

    chars: mutable Vector<Char> = mutable Vector[];
    iter = line.getIter();
    repeat = loop {
      c = iter.next() match {
      | None() ->
        print_error("Error: unexpected end of line");
        skipExit(23)
      | Some(x) -> x
      };
      if (c == '\t') {
        break String::fromChars(chars.toArray()).toInt()
      };
      if (c < '0' || c > '9') {
        print_error("Error: expected an integer");
        skipExit(23)
      };
      chars.push(c);
    };

    // parse out the remainder of the line - the csv values
    str = line.sub(iter, line.length() - chars.size() - 1);
    values = mutable Vector[];
    strIter = str.getIter();
    next = () -> {
      val = strIter.next();
      val match {
      | None() -> '\n'
      | Some(x) -> x
      }
    };
    for (value in lex(next)) {
      values.push(value);
    };
    cvalues = values.map(parseCSVValue);
    // empty params since no placeholders in skdb diff write-csv
    params: Map<String, P.Value> = Map[];
    SKDB.computeInsert(
      context.mclone(),
      params,
      false,
      0,
      None(),
      Array[cvalues.toArray()],
      table,
      repeat,
    );
  })
}

mutable class TableDiff(
  table: SKDB.DirDescr,
  snapshot: ?Int,
  mutable reset: Bool,
  rows: mutable Vector<SKDB.RowValues>,
  lines: mutable Vector<String>,
) {
  static fun create(table: SKDB.DirDescr, snapshot: ?Int): mutable this {
    mutable static(table, snapshot, false, mutable Vector[], mutable Vector[])
  }
}

fun buildDiffChain(
  tableDiffs: readonly Vector<mutable TableDiff>,
  identity: Int,
  userFileOpt: ?SKDB.UserFile,
  checkpoint: Int,
): ?((
  mutable SKStore.Context,
  mutable SKStore.Context,
  SKStore.Context,
) ~> void) {
  strategies = tableDiffs.map(td -> {
    applyDiffStrategy(
      td.table,
      identity,
      userFileOpt,
      td.reset,
      td.rows.toArray(),
      Some(checkpoint),
      td.snapshot,
    );
  });
  Some((newRoot, delta, root) ~> {
    for (strategy in strategies) {
      if (strategy is Some _) {
        strategy.fromSome()(newRoot, delta, root)
      }
    }
  })
}

mutable class DiffParsingState(
  tableDiffs: mutable Vector<mutable TableDiff>,
  currentDiff: mutable TableDiff,
)

fun nack(writer: mutable Debug.BufferedWriter, diff: readonly TableDiff): void {
  writer.write("^" + SKDB.feedbackTable(diff.table.name.origName) + "\n");
  for (line in diff.lines) {
    writer.write(line);
    writer.write("\n")
  }
}

fun replayDiff(
  context: mutable SKStore.Context,
  getLine: () -> ?String,
  user: ?String,
  identity: Int,
): SKStore.ContextOp {
  SKDB.getFinalState(context, Some(identity)) match {
  | Some(SKDB.RSError()) ->
    print_raw(":reboot\n");
    return SKStore.CStop(None())
  | _ -> void
  };

  immContext = context.clone();
  userFileOpt = user.map(x -> SKDB.UserFile::create(context, x));
  state: ?(mutable DiffParsingState) = None();
  try {
    loop {
      line = getLine() match {
      | Some(l) -> l
      | None() -> break SKStore.CStop(None())
      };
      !state = state match {
      | None() if (String.getByte(line, 0) != 94) -> // !startsWith("^")
        None()

      | None() ->
        (table, snapshot) = parseHeader(context, line);
        Some(
          mutable DiffParsingState(
            mutable Vector[],
            TableDiff::create(table, snapshot),
          ),
        )

      | Some(
        DiffParsingState(tableDiffs, currentDiff),
      ) if (String.getByte(line, 0) == 94) -> // startsWith("^")
        (table, snapshot) = parseHeader(context, line);
        tableDiffs.push(currentDiff);
        Some(
          mutable DiffParsingState(
            tableDiffs,
            TableDiff::create(table, snapshot),
          ),
        )

      | Some(
        DiffParsingState(tableDiffs, currentDiff),
      ) if (String.getByte(line, 0) == 58) -> // startsWith(":")
        currentDiff.lines.push(line);
        tableDiffs.push(currentDiff);
        checkpoint = parseCheckpoint(line);

        rejectedAnyDiff = false;
        userFileOpt.each(userFile ->
          SKStore.withContext(privacyContext -> {
            accessSolver = SKDB.AccessSolver::create(
              privacyContext,
              userFile.name,
            );
            for (diff in tableDiffs) {
              if (rejectedAnyDiff) {
                break void
              };
              tableName = diff.table.name.origName;
              authorCol = SKDB.getAuthorIdx(diff.table);
              accessCol = SKDB.getAccessIdx(diff.table);
              for (row in diff.rows) {
                SKDB.checkUserCanWriteRow(
                  privacyContext,
                  accessSolver,
                  tableName,
                  authorCol,
                  accessCol,
                  row,
                ) match {
                | SKDB.AROK() -> void
                | SKDB.ARError(err) ->
                  print_error("Error: " + err.toString());
                  !rejectedAnyDiff = true;
                  break void
                }
              };
            };
          })
        );
        if (rejectedAnyDiff) {
          writer = mutable Debug.BufferedWriter(print_raw, 4096);
          for (tdiff in tableDiffs) {
            nack(writer, tdiff)
          };
          writer.flush();
          break SKStore.CContinue(None())
        } else {
          break SKStore.CContinue(
            buildDiffChain(tableDiffs, identity, userFileOpt, checkpoint),
          )
        }

      | current @ Some(DiffParsingState(_, currentDiff)) if (line == "\t\t") ->
        currentDiff.!reset = true;
        current

      | current @ Some(DiffParsingState(_, currentDiff)) ->
        currentDiff.lines.push(line); // capture the raw input for if we end up rejecting the txn
        newRows = parseTableChange(immContext, currentDiff.table, line);
        currentDiff.rows.extend(newRows);
        current
      };
    }
  } catch {
  | EndOfFile _ ->
    // we expect streams to be cut, not an error. but let's not
    // apply changes that aren't guaranteed complete and consistent.
    SKStore.CStop(None())
  | SKDB.IgnoreAndContinue _ ->
    flushStdout();
    SKStore.CContinue(None())
  | exn ->
    print_error(exn.getMessage());
    SKStore.CStop(None())
  }
}

fun replayStdin(): Map<String, (Int, Int)> {
  txNbr = 0;
  all = mutable Map<String, (Int, Int)>[];
  tx = mutable Map<String, (Int, Int)>[];
  commit = () -> {
    for (x => y in tx) {
      all![x] = y
    };
    tx.clear();
    !txNbr = txNbr + 1;
  };
  lineNbr = 1;
  loop {
    line = read_line() match {
    | None() -> break all.chill()
    | Some("") -> continue
    | Some(l) -> l
    };
    chars: mutable Vector<Char> = mutable Vector[];
    iter = line.getIter();
    header = false;
    checkpoint = false;
    reset = false;
    loop {
      c = iter.next() match {
      | None() ->
        print_error("Error, line " + lineNbr + ": unexpected end of line");
        skipExit(23)
      | Some('^') ->
        !header = true;
        break void
      | Some(':') ->
        !checkpoint = true;
        break void
      | Some(x) -> x
      };
      if (c == '\t') {
        if (chars.size() == 0 || chars[0] == '\t') {
          !reset = true;
          break void
        } else {
          break void
        }
      };
      if (c < '0' || c > '9') {
        print_error("Error, line " + lineNbr + ": expected an integer key");
        skipExit(23)
      };
      chars.push(c);
    };
    if (header) {
      continue;
    };
    if (reset) {
      all.clear();
      commit();
      continue;
    };
    if (checkpoint) {
      commit();
      continue;
    };
    repeat = String::fromChars(chars.toArray()).toInt();
    value = line.sub(iter, line.length() - chars.size() - 1);
    tx![value] = (txNbr, repeat);
    !lineNbr = lineNbr + 1;
  }
}

module end;
